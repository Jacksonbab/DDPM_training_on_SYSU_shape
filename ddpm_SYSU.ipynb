{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398c3e5b-8213-4b00-ab61-108563a321c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: denoising_diffusion_pytorch in /home/kyq5pg/.local/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: accelerate in /home/kyq5pg/.local/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (1.1.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (0.8.0)\n",
      "Requirement already satisfied: ema-pytorch>=0.4.2 in /home/kyq5pg/.local/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (0.7.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (1.24.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (9.5.0)\n",
      "Requirement already satisfied: pytorch-fid in /home/kyq5pg/.local/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (0.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (1.13.0)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (2.4.0a0+07cecf4168.nv24.5)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (0.19.0a0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (4.66.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from accelerate->denoising_diffusion_pytorch) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising_diffusion_pytorch) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising_diffusion_pytorch) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising_diffusion_pytorch) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/kyq5pg/.local/lib/python3.10/site-packages (from accelerate->denoising_diffusion_pytorch) (0.4.5)\n",
      "Requirement already satisfied: requests in /home/kyq5pg/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->denoising_diffusion_pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->denoising_diffusion_pytorch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install denoising_diffusion_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa83379a-dde3-4288-b616-83f6c1b8b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_sysu_shape_dataset(\n",
    "    dataset_path,\n",
    "    train_path,\n",
    "    eval_path,\n",
    "    image_size=128,\n",
    "    eval_ratio=0.2,\n",
    "    batch_size=32\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare and preprocess the SYSU-Shape dataset for DDPM training, \n",
    "    saving resized images.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path (str): Path to the root of the SYSU-Shape dataset.\n",
    "        train_path (str): Path to store the processed training data.\n",
    "        eval_path (str): Path to store the processed evaluation data.\n",
    "        image_size (int): Target size for resizing images.\n",
    "        eval_ratio (float): Proportion of images to use for evaluation.\n",
    "        batch_size (int): Batch size for DataLoader.\n",
    "    \n",
    "    Returns:\n",
    "        DataLoader: DataLoader for training and evaluation datasets.\n",
    "    \"\"\"\n",
    "    categories = ['car', 'boat', 'motorbike', 'airplane', 'bicycle']\n",
    "    \n",
    "    # Clear existing directories to avoid appending\n",
    "    if os.path.exists(train_path):\n",
    "        shutil.rmtree(train_path)  # Delete train_path directory\n",
    "    if os.path.exists(eval_path):\n",
    "        shutil.rmtree(eval_path)  # Delete eval_path directory\n",
    "    \n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(eval_path, exist_ok=True)\n",
    "\n",
    "    # separate the process of resize and toTensor and normalize, \n",
    "    # therefore, we let the images stored also being resized\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size))  # Resize to fixed size\n",
    "    ])\n",
    "    \n",
    "    for category in categories:\n",
    "        image_dir = os.path.join(dataset_path, category, 'images')\n",
    "        images = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "        random.shuffle(images)\n",
    "        eval_size = int(len(images) * eval_ratio)\n",
    "\n",
    "        # Split images\n",
    "        eval_images = images[:eval_size]\n",
    "        train_images = images[eval_size:]\n",
    "\n",
    "        # Process and save resized images\n",
    "        for img_set, output_dir in [(train_images, train_path), (eval_images, eval_path)]:\n",
    "            category_path = os.path.join(output_dir, category)\n",
    "            os.makedirs(category_path, exist_ok=True)\n",
    "            \n",
    "            for img in img_set:\n",
    "                img_path = os.path.join(image_dir, img)\n",
    "                with Image.open(img_path) as image:\n",
    "                    resized_image = transform(image)  # Apply resizing transformation\n",
    "                    resized_image.save(os.path.join(category_path, img))  # Save resized image\n",
    "    \n",
    "    # Clean up unwanted folders in train and eval directories\n",
    "    for folder in [train_path, eval_path]:\n",
    "        for subdir in os.listdir(folder):\n",
    "            if subdir not in categories:  # If folder is not in the fixed categories\n",
    "                subdir_path = os.path.join(folder, subdir)\n",
    "                if os.path.isdir(subdir_path):  # Ensure it's a directory\n",
    "                    print(f\"Removing unwanted folder: {subdir_path}\")\n",
    "                    shutil.rmtree(subdir_path)\n",
    "                    \n",
    "    # Define preprocessing transformations for DataLoader\n",
    "    loader_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),                        # Convert to PyTorch tensor\n",
    "        transforms.Normalize((0.5,), (0.5,))          # Normalize to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # Create DataLoaders for training and evaluation datasets\n",
    "    train_dataset = datasets.ImageFolder(root=train_path, transform=loader_transform)\n",
    "    eval_dataset = datasets.ImageFolder(root=eval_path, transform=loader_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, eval_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c0ae84-952c-472d-a898-d82b23cf7afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call the method\n",
    "train_loader, eval_loader = prepare_sysu_shape_dataset(\n",
    "    dataset_path=\"./sysu-shape-dataset\",\n",
    "    train_path=\"./processed-datasets/train_data\",\n",
    "    eval_path=\"./processed-datasets/eval_data\",\n",
    "    eval_ratio=0.2,\n",
    "    image_size=128,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dedc62-3866-4775-95c9-ea9b4c1134b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1f9bf10-52df-4bf0-a47c-ec37d6d12cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40338861cc841c8b9a8a1c43f33825f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_185834/2543318879.py\", line 29, in <module>\n",
      "    trainer.train()\n",
      "  File \"/home/kyq5pg/.local/lib/python3.10/site-packages/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py\", line 1062, in train\n",
      "    self.accelerator.backward(loss)\n",
      "  File \"/home/kyq5pg/.local/lib/python3.10/site-packages/accelerate/accelerator.py\", line 2237, in backward\n",
      "    self.scaler.scale(loss).backward(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 534, in backward\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 267, in backward\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\", line 767, in _engine_run_backward\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pygments/styles/__init__.py\", line 45, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1448, in structured_traceback\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1339, in structured_traceback\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1186, in structured_traceback\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1076, in format_exception_as_a_whole\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1127, in get_records\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pygments/styles/__init__.py\", line 47, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'pygments.styles.default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer\n",
    "\n",
    "# Define the U-Net model\n",
    "model = Unet(\n",
    "    dim=64,  # Base feature map size\n",
    "    dim_mults=(1, 2, 4, 8)  # U-Net mults\n",
    ")\n",
    "\n",
    "# Define the diffusion process\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size=128,         # Image size\n",
    "    timesteps=1000,         # Total diffusion timesteps\n",
    "    sampling_timesteps=250  # Sampling timesteps (for faster sampling)\n",
    ")\n",
    "\n",
    "# Trainer configuration\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    './processed-datasets/train_data',\n",
    "    train_lr = 8e-5,\n",
    "    train_num_steps = 700000,         # total training steps\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    amp = True,                       # turn on mixed precision\n",
    "    calculate_fid = True              # whether to calculate fid during training\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ee930-9b15-4e50-b7a2-11cf05c30230",
   "metadata": {},
   "source": [
    "### Try to use multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec9ae1-e876-4dd4-80a2-60f00c91d756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer\n",
    "\n",
    "# Define the U-Net model\n",
    "model = Unet(\n",
    "    dim=64,  # Base feature map size\n",
    "    dim_mults=(1, 2, 4, 8)  # U-Net mults\n",
    ")\n",
    "\n",
    "# Define the diffusion process (wrap the unwrapped model)\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size=128,         # Image size\n",
    "    timesteps=1000,         # Total diffusion timesteps\n",
    "    sampling_timesteps=250  # Sampling timesteps (for faster sampling)\n",
    ")\n",
    "\n",
    "# Wrap model with DataParallel after creating the diffusion instance\n",
    "diffusion.model = torch.nn.DataParallel(diffusion.model).cuda()\n",
    "\n",
    "# Trainer configuration\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    './processed-datasets/train_data',\n",
    "    train_lr=8e-5,\n",
    "    train_num_steps=700000,         # total training steps\n",
    "    gradient_accumulate_every=2,    # gradient accumulation steps\n",
    "    ema_decay=0.995,                # exponential moving average decay\n",
    "    amp=True,                       # turn on mixed precision\n",
    "    calculate_fid=True              # whether to calculate fid during training\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6803ff7d-6289-4f03-8460-2b3c90cbe06b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
