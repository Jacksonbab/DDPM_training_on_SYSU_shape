{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398c3e5b-8213-4b00-ab61-108563a321c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: denoising_diffusion_pytorch in /home/kyq5pg/.local/lib/python3.10/site-packages (2.1.1)\n",
      "Requirement already satisfied: accelerate in /home/kyq5pg/.local/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (1.1.1)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (0.8.0)\n",
      "Requirement already satisfied: ema-pytorch>=0.4.2 in /home/kyq5pg/.local/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (0.7.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (1.24.4)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (9.5.0)\n",
      "Requirement already satisfied: pytorch-fid in /home/kyq5pg/.local/lib/python3.10/site-packages (from denoising_diffusion_pytorch) (0.3.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (1.13.0)\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (2.4.0a0+07cecf4168.nv24.5)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (0.19.0a0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from denoising_diffusion_pytorch) (4.66.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->denoising_diffusion_pytorch) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/kyq5pg/.local/lib/python3.10/site-packages (from accelerate->denoising_diffusion_pytorch) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising_diffusion_pytorch) (24.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising_diffusion_pytorch) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->denoising_diffusion_pytorch) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/kyq5pg/.local/lib/python3.10/site-packages (from accelerate->denoising_diffusion_pytorch) (0.4.5)\n",
      "Requirement already satisfied: requests in /home/kyq5pg/.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->denoising_diffusion_pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->denoising_diffusion_pytorch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate->denoising_diffusion_pytorch) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install denoising_diffusion_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa83379a-dde3-4288-b616-83f6c1b8b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_sysu_shape_dataset(\n",
    "    dataset_path,\n",
    "    train_path,\n",
    "    eval_path,\n",
    "    image_size=128,\n",
    "    eval_ratio=0.2,\n",
    "    batch_size=32\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare and preprocess the SYSU-Shape dataset for DDPM training, \n",
    "    saving resized images.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path (str): Path to the root of the SYSU-Shape dataset.\n",
    "        train_path (str): Path to store the processed training data.\n",
    "        eval_path (str): Path to store the processed evaluation data.\n",
    "        image_size (int): Target size for resizing images.\n",
    "        eval_ratio (float): Proportion of images to use for evaluation.\n",
    "        batch_size (int): Batch size for DataLoader.\n",
    "    \n",
    "    Returns:\n",
    "        DataLoader: DataLoader for training and evaluation datasets.\n",
    "    \"\"\"\n",
    "    categories = ['car', 'boat', 'motorbike', 'airplane', 'bicycle']\n",
    "    \n",
    "    # Clear existing directories to avoid appending\n",
    "    if os.path.exists(train_path):\n",
    "        shutil.rmtree(train_path)  # Delete train_path directory\n",
    "    if os.path.exists(eval_path):\n",
    "        shutil.rmtree(eval_path)  # Delete eval_path directory\n",
    "    \n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(eval_path, exist_ok=True)\n",
    "\n",
    "    # separate the process of resize and toTensor and normalize, \n",
    "    # therefore, we let the images stored also being resized\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size))  # Resize to fixed size\n",
    "    ])\n",
    "    \n",
    "    for category in categories:\n",
    "        image_dir = os.path.join(dataset_path, category, 'images')\n",
    "        images = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "        random.shuffle(images)\n",
    "        eval_size = int(len(images) * eval_ratio)\n",
    "\n",
    "        # Split images\n",
    "        eval_images = images[:eval_size]\n",
    "        train_images = images[eval_size:]\n",
    "\n",
    "        # Process and save resized images\n",
    "        for img_set, output_dir in [(train_images, train_path), (eval_images, eval_path)]:\n",
    "            category_path = os.path.join(output_dir, category)\n",
    "            os.makedirs(category_path, exist_ok=True)\n",
    "            \n",
    "            for img in img_set:\n",
    "                img_path = os.path.join(image_dir, img)\n",
    "                with Image.open(img_path) as image:\n",
    "                    resized_image = transform(image)  # Apply resizing transformation\n",
    "                    resized_image.save(os.path.join(category_path, img))  # Save resized image\n",
    "    \n",
    "    # Clean up unwanted folders in train and eval directories\n",
    "    for folder in [train_path, eval_path]:\n",
    "        for subdir in os.listdir(folder):\n",
    "            if subdir not in categories:  # If folder is not in the fixed categories\n",
    "                subdir_path = os.path.join(folder, subdir)\n",
    "                if os.path.isdir(subdir_path):  # Ensure it's a directory\n",
    "                    print(f\"Removing unwanted folder: {subdir_path}\")\n",
    "                    shutil.rmtree(subdir_path)\n",
    "                    \n",
    "    # Define preprocessing transformations for DataLoader\n",
    "    loader_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),                        # Convert to PyTorch tensor\n",
    "        transforms.Normalize((0.5,), (0.5,))          # Normalize to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # Create DataLoaders for training and evaluation datasets\n",
    "    train_dataset = datasets.ImageFolder(root=train_path, transform=loader_transform)\n",
    "    eval_dataset = datasets.ImageFolder(root=eval_path, transform=loader_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, eval_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c0ae84-952c-472d-a898-d82b23cf7afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call the method\n",
    "train_loader, eval_loader = prepare_sysu_shape_dataset(\n",
    "    dataset_path=\"./sysu-shape-dataset\",\n",
    "    train_path=\"./processed-datasets/train_data\",\n",
    "    eval_path=\"./processed-datasets/eval_data\",\n",
    "    eval_ratio=0.2,\n",
    "    image_size=128,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e09a3-1dbe-4853-98bd-859f2ade8ad3",
   "metadata": {},
   "source": [
    "We have to move images of all categories (now in subdirs) into the root dir of eval_data, this is required by the pytorch-fid calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5dedc62-3866-4775-95c9-ea9b4c1134b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have been moved to the root of ./processed-datasets/eval_data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def flatten_directory(root_dir):\n",
    "    \"\"\"\n",
    "    Moves all images from subdirectories of the root directory to the root directory.\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): Path to the root directory to flatten.\n",
    "    \"\"\"\n",
    "    for subdir in os.listdir(root_dir):\n",
    "        subdir_path = os.path.join(root_dir, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            for filename in os.listdir(subdir_path):\n",
    "                file_path = os.path.join(subdir_path, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    # Move the file to the root directory\n",
    "                    shutil.move(file_path, os.path.join(root_dir, filename))\n",
    "            # Remove the now-empty subdirectory\n",
    "            os.rmdir(subdir_path)\n",
    "\n",
    "# Example usage\n",
    "eval_data_dir = \"./processed-datasets/eval_data\"\n",
    "flatten_directory(eval_data_dir)\n",
    "print(f\"All images have been moved to the root of {eval_data_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ce94c-1cd3-4279-bf4a-ac8bf2d5baa0",
   "metadata": {},
   "source": [
    "normalize the evaluation images to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e28b8bbd-1fa2-4ec6-9f1a-ba6256ba6a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized images saved to ./processed-datasets/normalized_eval_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def normalize_images_to_unit_range(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Normalize images in the input directory to [0, 1] and save them in the output directory.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to the directory containing the images to normalize.\n",
    "        output_dir (str): Path to the directory where normalized images will be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                try:\n",
    "                    input_path = os.path.join(root, file)\n",
    "                    output_path = os.path.join(output_dir, file)\n",
    "\n",
    "                    # Open and normalize image\n",
    "                    img = Image.open(input_path).convert(\"RGB\")\n",
    "                    img = img.resize((128, 128))  # Ensure images are the same size\n",
    "                    img = (np.asarray(img) / 255.0).clip(0, 1)  # Normalize to [0, 1]\n",
    "\n",
    "                    # Save the normalized image\n",
    "                    normalized_img = Image.fromarray((img * 255).astype(\"uint8\"))\n",
    "                    normalized_img.save(output_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {file}: {e}\")\n",
    "\n",
    "# Paths for the real images\n",
    "eval_data_dir = \"./processed-datasets/eval_data\"\n",
    "normalized_eval_data_dir = \"./processed-datasets/normalized_eval_data\"\n",
    "\n",
    "normalize_images_to_unit_range(eval_data_dir, normalized_eval_data_dir)\n",
    "\n",
    "print(f\"Normalized images saved to {normalized_eval_data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee219382-26b4-4dfd-97ea-3f900d08d1a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5638b9e7-e7a0-4732-aaee-30e86e1a0158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def check_image_preprocessing(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            try:\n",
    "                img = Image.open(os.path.join(root, file))\n",
    "                img_array = np.asarray(img)  # Convert to numpy array\n",
    "                print(f\"{file}: min={img_array.min()}, max={img_array.max()}, shape={img_array.shape}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Check real images\n",
    "# check_image_preprocessing(\"./processed-datasets/normalized_eval_data\")\n",
    "\n",
    "# # Check generated images\n",
    "# check_image_preprocessing(\"/scratch/kyq5pg/MLIA_final/samples/model-70\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a91ab-4ec1-495e-b480-8f36548d67a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.4.0",
   "language": "python",
   "name": "pytorch-2.4.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
